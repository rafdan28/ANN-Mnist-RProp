{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# UNIVERSITA' DEGLI STUDI DI NAPOLI FEDERICO II\n",
    "# NEURAL NETWORK AND DEEP LEARNING\n",
    "## Authors\n",
    "\n",
    "    Giuseppe Cicchella N97000452\n",
    "    Raffaele D'Anna N97000455\n",
    "    \n",
    "# Confronto tra l’algoritmo classico di RProp e le sue varianti per la classificazione di immagini MNIST\n",
    "\n",
    "Questo quaderno Jupyter offre un ambiente interattivo per l’addestramento e l’analisi di reti neurali applicate alla classificazione delle cifre del dataset MNIST, permettendo agli utenti di esplorare diverse configurazioni di reti e algoritmi di ottimizzazione, con particolare focus sulle varianti dell’algoritmo Rprop (STANDARD, RPROP_PLUS, IRPROP).\n",
    "\n",
    "## Sommario\n",
    "    \n",
    "    1. Estrazione e Preparazione del Dataset MNIST\n",
    "\t2. Configurazione delle Reti Neurali\n",
    "\t3. Addestramento con Varianti di Rprop\n",
    "\t4. Valutazione delle Prestazioni con Grafici\n",
    "\n",
    "## Configurazioni delle Reti Neurali\n",
    "\n",
    "Gli utenti possono personalizzare la struttura delle reti neurali scegliendo tra diverse configurazioni, inclusa la possibilità di definire:\n",
    "\n",
    "    • Dimensioni del training e del test set.\n",
    "\t• Numero di strati nascosti.\n",
    "\t• Numero di neuroni per strato.\n",
    "\t• Funzioni di attivazione per ciascun livello.\n",
    "\t\n",
    "## Personalizzazione dei Parametri di Addestramento\n",
    "\n",
    "Il quaderno permette una flessibile impostazione dei parametri di addestramento, quali:\n",
    "\n",
    "\t• Numero di epoche.\n",
    "\t• Tasso di apprendimento.\n",
    "\t• Suddivisione del set di addestramento.\n",
    "\t• Numero di ripetizioni, per eseguire più volte l’addestramento con una configurazione fissa, consentendo una valutazione più accurata degli algoritmi.\n",
    "\n",
    "## Algoritmi di Ottimizzazione Rprop\n",
    "\n",
    "Sono implementate diverse varianti dell’algoritmo di ottimizzazione Rprop, che possono essere confrontate in termini di efficienza e prestazioni durante l’addestramento delle reti neurali.\n",
    "\n",
    "## Valutazione delle Prestazioni delle Reti Neurali\n",
    "\n",
    "Il quaderno fornisce un’analisi completa delle prestazioni delle reti, con le seguenti metriche:\n",
    "       \n",
    "    • Tempo di impiegato per l'addestramento complessivo.\n",
    "\t• Errore sui set di addestramento e validazione.\n",
    "\t• Accuratezza sui set di addestramento, validazione e test.\n",
    "\t• Media, Varianza delle Accuratezze sui set di test e addestramento.\n",
    "\t"
   ],
   "id": "1490f01ac98a5079"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\"\"\"\n",
    "    1. Estrazione e Preparazione del Dataset MNIST\n",
    "\"\"\"\n",
    "\n",
    "from nndlpy import MnistDataset as MnistDataset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\"\"\"\n",
    "    Init\n",
    "\"\"\"\n",
    "# Carica il dataset MNIST CSV con pandas\n",
    "train_data = pd.read_csv('data/mnist_train.csv')\n",
    "test_data = pd.read_csv('data/mnist_test.csv')\n",
    "\n",
    "# Converti i dati in array con numpy\n",
    "train_array = np.array(train_data)\n",
    "test_array = np.array(test_data)\n",
    "\n",
    "# Definisci le dimensioni del training e test set\n",
    "train_set_size = 50000  # Almeno 10.000 campioni per il training\n",
    "test_set_size = 10000    # Almeno 2.500 campioni per il test\n",
    "\n",
    "\"\"\"\n",
    "    Validation Set\n",
    "\"\"\"\n",
    "# Mescola i dati di training casualmente\n",
    "np.random.shuffle(train_array)\n",
    "# Calcola l'indice per il validation set (esempio: il 20% del training set)\n",
    "val_index = int(np.ceil(train_set_size * 0.20))\n",
    "# Estrai il validation set dal training array\n",
    "validation_array = train_array[:val_index - 1]\n",
    "# Estrai il validation set\n",
    "validation_X, validation_Y = MnistDataset.get_mnist_validation(validation_array)\n",
    "\n",
    "\"\"\"\n",
    "    Training Set\n",
    "\"\"\"\n",
    "# Estrai il training set rimanente (senza i dati di validation)\n",
    "train_array_reduced = train_array[val_index:train_set_size]\n",
    "# Estrai il training set (dopo aver rimosso i dati di validazione)\n",
    "train_X, train_Y = MnistDataset.get_mnist_training(train_array_reduced)\n",
    "\n",
    "\"\"\"\n",
    "    Test Set\n",
    "\"\"\"\n",
    "# Estrai il test set direttamente dal file di test\n",
    "test_X, test_Y = MnistDataset.get_mnist_test(test_array, test_set_size)\n",
    "\n",
    "print(\"\\nEstrazione e Preparazione del Dataset MNIST avvenuta con successo.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "    2. Configurazione delle Reti Neurali\n",
    "\"\"\"\n",
    "\n",
    "from nndlpy import ActivationFunctions as ActivationFunctions\n",
    "from nndlpy import LossFunctions as LossFunctions\n",
    "from nndlpy import NeuralNetwork as NeuralNetwork\n",
    "\n",
    "# Parametri di addestramento\n",
    "epochs = 3\n",
    "learning_rate = 0.00001\n",
    "num_of_networks = 2  # Definisci quante reti testare (maggiore di 0)\n",
    "\n",
    "# Funzioni di attivazione per i layer nascosti\n",
    "hidden_activation_funcs = [ActivationFunctions.relu]\n",
    "# Funzione di attivazione per l'output\n",
    "output_activation_func = ActivationFunctions.identity\n",
    "#Funzione di perdita per l'output\n",
    "loss_func = LossFunctions.cross_entropy_softmax\n",
    "\n",
    "# Numero di neuroni per ciascun layer nascosto\n",
    "hidden_layers_sizes = [32]\n",
    "\n",
    "# Dimensione dell'input e dell'output (numero di neuroni nel primo e ultimo layer)\n",
    "input_layer_size = train_X.shape[0]\n",
    "output_layer_size = train_Y.shape[0]\n",
    "\n",
    "# Creazione e inizializzazione delle reti neurali\n",
    "neural_networks = []\n",
    "\n",
    "for run in range(num_of_networks):\n",
    "    try:\n",
    "        # Inizializza una nuova rete neurale con la configurazione corrente\n",
    "        network = NeuralNetwork.NeuralNetwork(\n",
    "            hidden_activation_funcs,\n",
    "            output_activation_func,\n",
    "            loss_func,\n",
    "            input_layer_size,\n",
    "            hidden_layers_sizes,\n",
    "            output_layer_size\n",
    "        )\n",
    "        print(f\"Rete neurale {run + 1} inizializzata con successo.\")\n",
    "    except ValueError as exception:\n",
    "        print(f\"Errore durante l'inizializzazione della rete {run + 1}: {exception}\")\n",
    "        continue\n",
    "    \n",
    "    # Aggiungi la rete neurale alla lista di reti\n",
    "    neural_networks.append(network)\n",
    "\n",
    "    # Modifica l'architettura rimuovendo l'ultima funzione di attivazione per la prossima rete (se necessario)\n",
    "    if hidden_activation_funcs:\n",
    "        hidden_activation_funcs = hidden_activation_funcs[:-1]\n",
    "    \n",
    "# Mostra la struttura della prima rete\n",
    "print(\"\\nArchitettura della prima rete:\")\n",
    "neural_networks[0].get_network()"
   ],
   "id": "f1903c689d85edb6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "    3. Addestramento con Varianti di Rprop (STANDARD, RPROP_PLUS, IRPROP)\n",
    "\"\"\"\n",
    "\n",
    "from src.nndlpy.NeuralNetwork import calculate_mean_and_variance\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Inizializza le liste per memorizzare le metriche per ogni metodo Rprop\n",
    "std_metrics_mean = []\n",
    "plus_metrics_mean = []\n",
    "istd_metrics_mean = []\n",
    "\n",
    "# Definisci i metodi Rprop da utilizzare\n",
    "rprop_methods = ['STANDARD', 'RPROP_PLUS', 'IRPROP']\n",
    "average_training_times = []\n",
    "\n",
    "# Creazione di una lista per contenere le metriche di ogni run\n",
    "metrics_per_rprop_method = []\n",
    "\n",
    "# Ciclo sui metodi Rprop\n",
    "for rprop_method in rprop_methods:\n",
    "    print(f'\\nInizio addestramento con Rprop metodo: {rprop_method}')\n",
    "\n",
    "    total_training_time = 0\n",
    "    std_test_accuracies = []\n",
    "    \n",
    "    results_metrics = []\n",
    "    trained_networks = []\n",
    "    \n",
    "    # Esegui il ciclo per il numero di reti specificato\n",
    "    for run in range(num_of_networks):\n",
    "        training_network = neural_networks[run].clone_network()\n",
    "        print(f'\\nEsecuzione numero {run + 1} per il metodo {rprop_method}')\n",
    "\n",
    "        # Addestramento utilizzando il metodo Rprop corrente\n",
    "        metrics = training_network.train_model(train_X, train_Y, validation_X, validation_Y,\n",
    "                                               num_epochs=epochs, learning_rate=learning_rate,\n",
    "                                               rprop_method=rprop_method)\n",
    "\n",
    "        # Salva la rete addestrata e i risultati\n",
    "        trained_networks.append(training_network)\n",
    "        results_metrics.append(metrics)\n",
    "\n",
    "        # Stampa dell'accuratezza\n",
    "        std_test_accuracies.append(training_network.print_accuracies(f'\\nTest {rprop_method} - Run {run + 1}', \n",
    "                                                                     test_X, test_Y, train_X, train_Y))\n",
    "\n",
    "        total_training_time += round(metrics[4], 5)  # metrics[4] è elapsed_time\n",
    "\n",
    "    # Calcola media e varianza delle metriche\n",
    "    metrics_mean, metrics_variance, last_metrics_mean, last_metrics_variance = calculate_mean_and_variance(results_metrics, epochs, num_of_networks)\n",
    "    \n",
    "    # Aggiungi le metriche medie e la varianza alla lista principale per ogni metodo Rprop\n",
    "    metrics_per_rprop_method.append({\n",
    "        'method': rprop_method,\n",
    "        'mean': metrics_mean,\n",
    "        'variance': metrics_variance,\n",
    "        'last_mean': last_metrics_mean,\n",
    "        'last_variance': last_metrics_variance\n",
    "    })\n",
    "\n",
    "    # Salva le metriche medie per ogni metodo\n",
    "    if rprop_method == 'STANDARD':\n",
    "        std_metrics_mean = metrics_mean\n",
    "    elif rprop_method == 'RPROP_PLUS':\n",
    "        plus_metrics_mean = metrics_mean\n",
    "    elif rprop_method == 'IRPROP':\n",
    "        istd_metrics_mean = metrics_mean\n",
    "\n",
    "    # Calcola il tempo medio di addestramento\n",
    "    average_training_time = total_training_time / num_of_networks\n",
    "    average_training_times.append(average_training_time)\n",
    "    print(f'Tempo medio di addestramento per {rprop_method}: {round(average_training_time, 5)} secondi')\n"
   ],
   "id": "5c57894442ce52f2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Mostra la Media e la Varianza delle metriche per ogni metodo Rprop\n",
    "for metrics_data in metrics_per_rprop_method:\n",
    "    print(f\"\\nMetodo Rprop: {metrics_data['method']}\")\n",
    "    for i, metric_name in enumerate( [\"Errore sul Training Set\", \"Errore sul Validation Set\", \"Accuratezza sul Training Set \", \"Accuratezza sul Validation Test\"]):\n",
    "        print(f\"{metric_name}:\")\n",
    "        print(f\"Media finale: {metrics_data['last_mean'][i]}\")\n",
    "        print(f\"Varianza finale: {metrics_data['last_variance'][i]}\")\n",
    "        print()"
   ],
   "id": "91c8af1d9626ec0d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "    4. Valutazione delle Prestazioni con Grafici sul Tempo Medio di Addestramento, Errore Medio e Accuratezza media su Training e Validation Set \n",
    "\"\"\"\n",
    "import os\n",
    "\n",
    "path = f'results/[{num_of_networks}]Reti/{hidden_layers_sizes}Neuroni'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "            \n",
    "# Creazione e stampa del grafico del tempo medio di addestramento \n",
    "plt.style.use('bmh')\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(rprop_methods, average_training_times, color=['blue', 'orange', 'green'])\n",
    "plt.title(f'Tempi Medi di Addestramento per Varianti di RPROP\\n'\n",
    "          f'Neuroni: {\", \".join(map(str, hidden_layers_sizes))}, Reti: {num_of_networks}, Epoche: {epochs}')\n",
    "plt.xlabel('Metodi RPROP')\n",
    "plt.ylabel('Tempo Medio di Addestramento (s)')\n",
    "plt.grid(axis='y')\n",
    "plt.savefig(f'{path}/{\",\".join(map(str, hidden_layers_sizes))}_neuroni_{num_of_networks}_reti_{epochs}_epoche_tempo_medio_di_addestramento.png')\n",
    "plt.show()\n",
    "plt.close()"
   ],
   "id": "9d14e8f13a738226",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Creazione e stampa del grafico dell'errore medio del training set\n",
    "plt.style.use('bmh')\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(std_metrics_mean[0], 'b', label='STANDARD')\n",
    "plt.plot(plus_metrics_mean[0], 'r', label='RPROP_PLUS')\n",
    "plt.plot(istd_metrics_mean[0], 'y', label='IRPROP')\n",
    "plt.title(f'Errore medio su training set\\nNeuroni: {\", \".join(map(str, hidden_layers_sizes))} Reti: {num_of_networks}')\n",
    "plt.xlabel('Epoche')\n",
    "plt.ylabel('Errore')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xlim(0, epochs)\n",
    "plt.savefig(f'{path}/{\",\".join(map(str, hidden_layers_sizes))}_neuroni_errore_medio_training_set.png')\n",
    "plt.show()\n",
    "plt.close()"
   ],
   "id": "5c8263f9ed0f62f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Creazione e stampa del grafico dell'errore medio del validation set\n",
    "plt.style.use('bmh')\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(std_metrics_mean[1], 'b', label='STANDARD')\n",
    "plt.plot(plus_metrics_mean[1], 'r', label='RPROP_PLUS')\n",
    "plt.plot(istd_metrics_mean[1], 'y', label='IRPROP')\n",
    "plt.title(f'Errore medio su validation set\\nNeuroni: {\", \".join(map(str, hidden_layers_sizes))} Reti: {num_of_networks}')\n",
    "plt.xlabel('Epoche')\n",
    "plt.ylabel('Errore')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xlim(0, epochs)\n",
    "plt.savefig(f'{path}/{\",\".join(map(str, hidden_layers_sizes))}_neuroni_errore_medio_validation_set.png')\n",
    "plt.show()\n",
    "plt.close()"
   ],
   "id": "6258d443b4e887b6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Creazione e stampa del grafico dell'accuratezza media del training set\n",
    "plt.style.use('bmh')\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(std_metrics_mean[2], 'b', label='STANDARD')\n",
    "plt.plot(plus_metrics_mean[2], 'r', label='RPROP_PLUS')\n",
    "plt.plot(istd_metrics_mean[2], 'y', label='IRPROP')\n",
    "plt.title(f'Accuratezza media su training set\\nNeuroni: {\", \".join(map(str, hidden_layers_sizes))} Reti: {num_of_networks}')\n",
    "plt.xlabel('Epoche')\n",
    "plt.ylabel('Accuratezza')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.ylim(0, 1)\n",
    "plt.xlim(0, epochs)\n",
    "plt.savefig(f'{path}/{\",\".join(map(str, hidden_layers_sizes))}_neuroni_accuratezza_media_training_set.png')\n",
    "plt.show()\n",
    "plt.close()"
   ],
   "id": "a1ace235055b9d17",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Creazione e stampa del grafico dell'accuratezza media del validation set\n",
    "plt.style.use('bmh')\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(std_metrics_mean[3],  'b', label='STANDARD')\n",
    "plt.plot(plus_metrics_mean[3], 'r', label='RPROP_PLUS')\n",
    "plt.plot(istd_metrics_mean[3], 'y', label='IRPROP')\n",
    "plt.title(f'Accuratezza media su validation set\\nNeuroni: {\", \".join(map(str, hidden_layers_sizes))} Reti: {num_of_networks}')\n",
    "plt.xlabel('Epoche')\n",
    "plt.ylabel('Accuratezza')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.ylim(0, 1)\n",
    "plt.xlim(0, epochs)\n",
    "plt.savefig(f'{path}/{\",\".join(map(str, hidden_layers_sizes))}_neuroni_accuratezza_media_validation_set.png')\n",
    "plt.show()\n",
    "plt.close()"
   ],
   "id": "e93f07dcfa6713fc",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
