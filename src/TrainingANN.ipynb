{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Confronto tra l’algoritmo classico di RProp e le sue varianti per la classificazione di immagini MNIST\n",
    "\n",
    "Questo quaderno Jupyter offre un ambiente interattivo per l’addestramento e l’analisi di reti neurali applicate alla classificazione delle cifre del dataset MNIST, permettendo agli utenti di esplorare diverse configurazioni di reti e algoritmi di ottimizzazione, con particolare focus sulle varianti dell’algoritmo Rprop.\n",
    "\n",
    "## Sommario\n",
    "    \n",
    "    1. Estrazione e Preparazione del Dataset MNIST\n",
    "\t2. Configurazione delle Reti Neurali\n",
    "\t3. Addestramento con Varianti di Rprop\n",
    "\t4. Valutazione delle Prestazioni con Grafici\n",
    "\t5. Test Finale sul Set di Test\n",
    "\n",
    "## Configurazioni delle Reti Neurali\n",
    "\n",
    "Gli utenti possono personalizzare la struttura delle reti neurali scegliendo tra diverse configurazioni, inclusa la possibilità di definire:\n",
    "\n",
    "\t• Numero di strati nascosti.\n",
    "\t• Numero di neuroni per strato.\n",
    "\t• Funzioni di attivazione per ciascun livello.\n",
    "\t\n",
    "## Personalizzazione dei Parametri di Addestramento\n",
    "\n",
    "Il quaderno permette una flessibile impostazione dei parametri di addestramento, quali:\n",
    "\n",
    "\t• Numero di epoche.\n",
    "\t• Tasso di apprendimento.\n",
    "\t• Suddivisione del set di addestramento.\n",
    "\t•Numero di ripetizioni, per eseguire più volte l’addestramento con una configurazione fissa, consentendo una valutazione più accurata degli algoritmi.\n",
    "\n",
    "## Algoritmi di Ottimizzazione Rprop\n",
    "\n",
    "Sono implementate diverse varianti dell’algoritmo di ottimizzazione Rprop, che possono essere confrontate in termini di efficienza e prestazioni durante l’addestramento delle reti neurali.\n",
    "\n",
    "## Valutazione delle Prestazioni delle Reti Neurali\n",
    "\n",
    "Il quaderno fornisce un’analisi completa delle prestazioni delle reti, con le seguenti metriche:\n",
    "\n",
    "\t• Errore sui set di addestramento e validazione.\n",
    "\t• Accuratezza sui set di addestramento, validazione e test.\n",
    "\t• Tempo di esecuzione complessivo.\n",
    "\t• Media e varianza delle prestazioni su più ripetizioni, per valutare la stabilità e la consistenza degli algoritmi di ottimizzazione e delle configurazioni di rete."
   ],
   "id": "1490f01ac98a5079"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\"\"\"\n",
    "    1. Estrazione e Preparazione del Dataset MNIST\n",
    "\"\"\"\n",
    "\n",
    "from nndlpy import MnistDataset as MnistDataset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\"\"\"\n",
    "    Init\n",
    "\"\"\"\n",
    "# Carica il dataset MNIST CSV con pandas\n",
    "train_data = pd.read_csv('data/mnist_train.csv')\n",
    "test_data = pd.read_csv('data/mnist_test.csv')\n",
    "\n",
    "# Converti i dati in array con numpy\n",
    "train_array = np.array(train_data)\n",
    "test_array = np.array(test_data)\n",
    "\n",
    "# Definisci le dimensioni del training set\n",
    "train_set_size = 10000  # Almeno 10.000 campioni per il training\n",
    "test_set_size = 2500    # Almeno 2.500 campioni per il test\n",
    "\n",
    "\"\"\"\n",
    "    Validation Set\n",
    "\"\"\"\n",
    "# Mescola i dati di training casualmente\n",
    "np.random.shuffle(train_array)\n",
    "# Calcola l'indice per il validation set (esempio: il 20% del training set)\n",
    "val_index = int(np.ceil(train_set_size * 0.20))\n",
    "# Estrai il validation set dal training array\n",
    "validation_array = train_array[:val_index - 1]\n",
    "# Estrai il validation set\n",
    "validation_X, validation_Y = MnistDataset.get_mnist_validation(validation_array)\n",
    "\n",
    "\"\"\"\n",
    "    Training Set\n",
    "\"\"\"\n",
    "# Estrai il training set rimanente (senza i dati di validation)\n",
    "train_array_reduced = train_array[val_index:train_set_size]\n",
    "# Estrai il training set (dopo aver rimosso i dati di validazione)\n",
    "train_X, train_Y = MnistDataset.get_mnist_training(train_array_reduced)\n",
    "\n",
    "\"\"\"\n",
    "    Test Set\n",
    "\"\"\"\n",
    "# Estrai il test set direttamente dal file di test\n",
    "test_X, test_Y = MnistDataset.get_mnist_test(test_array, test_set_size)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "    2. Configurazione delle Reti Neurali\n",
    "\"\"\"\n",
    "\n",
    "from nndlpy import ActivationFunctions as ActivationFunctions\n",
    "from nndlpy import LossFunctions as LossFunctions\n",
    "from nndlpy import NeuralNetwork as NeuralNetwork\n",
    "\n",
    "# Parametri di addestramento\n",
    "epochs = 35\n",
    "learning_rate = 0.00001\n",
    "num_of_networks = 5  # Definisci quante reti testare (maggiore di 0)\n",
    "\n",
    "# Funzioni di attivazione per i layer nascosti\n",
    "hidden_activation_funcs = [ActivationFunctions.relu]\n",
    "# Funzione di attivazione per l'output\n",
    "output_activation_func = ActivationFunctions.identity\n",
    "#Funzione di perdita per l'output\n",
    "loss_func = LossFunctions.cross_entropy_softmax\n",
    "\n",
    "# Numero di neuroni per ciascun layer nascosto\n",
    "hidden_layers_sizes = [32]\n",
    "\n",
    "# Dimensione dell'input e dell'output (numero di neuroni nel primo e ultimo layer)\n",
    "input_layer_size = train_X.shape[0]\n",
    "output_layer_size = train_Y.shape[0]\n",
    "\n",
    "# Creazione e inizializzazione delle reti neurali\n",
    "neural_networks = []\n",
    "\n",
    "for i in range(num_of_networks):\n",
    "    try:\n",
    "        # Inizializza una nuova rete neurale con la configurazione corrente\n",
    "        network = NeuralNetwork.NeuralNetwork(\n",
    "            hidden_activation_funcs,\n",
    "            output_activation_func,\n",
    "            loss_func,\n",
    "            input_layer_size,\n",
    "            hidden_layers_sizes,\n",
    "            output_layer_size\n",
    "        )\n",
    "        print(f\"Rete neurale {i+1} inizializzata con successo.\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Errore durante l'inizializzazione della rete {i+1}: {e}\")\n",
    "        continue\n",
    "    \n",
    "    # Aggiungi la rete neurale alla lista di reti\n",
    "    neural_networks.append(network)\n",
    "\n",
    "    # Modifica l'architettura rimuovendo l'ultima funzione di attivazione per la prossima rete (se necessario)\n",
    "    # if hidden_activation_funcs:\n",
    "    #     hidden_activation_funcs = hidden_activation_funcs[:-1]\n",
    "    \n",
    "# Mostra la struttura della prima rete\n",
    "print(\"\\nArchitettura della prima rete:\")\n",
    "neural_networks[0].get_network()"
   ],
   "id": "f1903c689d85edb6",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from src.nndlpy.NeuralNetwork import plot_metrics\n",
    "\n",
    "# Inizializza due liste vuote per memorizzare i risultati e le reti addestrate\n",
    "results_metrics = []\n",
    "trained_networks = []\n",
    "\n",
    "# Esegui il ciclo per il numero di reti specificato\n",
    "for run in range(num_of_networks):\n",
    "    # Clona la rete neurale corrente per l'addestramento\n",
    "    training_network = neural_networks[run].clone_network()\n",
    "    print(f'\\n\\n\\nEsecuzione numero {run + 1}\\n')\n",
    "\n",
    "    # Addestramento utilizzando Rprop(Rprop può assumere i seguenti valori: STANDARD, RPROP_PLUS, IRPROP)\n",
    "    metrics = training_network.train_model(train_X, train_Y, validation_X, validation_Y,\n",
    "                                           num_epochs=epochs, learning_rate=learning_rate,\n",
    "                                           rprop_method='STANDARD')\n",
    "\n",
    "    # Salva la rete addestrata e i risultati\n",
    "    trained_networks.append(training_network)\n",
    "    results_metrics.append(metrics)\n",
    "\n",
    "# Chiamata alla funzione di visualizzazione\n",
    "plot_metrics(results_metrics)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1cf190ffe477e656",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Calcola le metriche \n",
    "    # MAE (Mean Absolute Error - Errore Assoluto Medio) \n",
    "    # RMSE (Root Mean Squared Error - Errore Quadratico Medio),\n",
    "    # Accuratezza \n",
    "# per le reti addestrate\n",
    "std_mae, std_rmse, std_accuracy = NeuralNetwork.metrics_mae_rmse_accuracy(results_metrics, epochs, num_of_networks)\n",
    "\n",
    "print(\"\\nErrore Assoluto Medio:\")\n",
    "print(f\"Media: {std_mae[-1]:.4f}\")\n",
    "\n",
    "print(\"\\nErrore Quadratico Medio:\")\n",
    "print(f\"Media: {std_rmse[-1]:.4f}\")\n",
    "\n",
    "print(\"\\nAccuratezza:\")\n",
    "print(f\"Media: {std_accuracy[-1]:.4f}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd91a036a32bc99",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
