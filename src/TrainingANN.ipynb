{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# UNIVERSITA' DEGLI STUDI DI NAPOLI FEDERICO II\n",
    "# NEURAL NETWORK AND DEEP LEARNING\n",
    "## Authors\n",
    "\n",
    "    Giuseppe Cicchella N97000452\n",
    "    Raffaele D'Anna N97000455\n",
    "    \n",
    "# Confronto tra l’algoritmo classico di RProp e le sue varianti per la classificazione di immagini MNIST\n",
    "\n",
    "Questo quaderno Jupyter offre un ambiente interattivo per l’addestramento e l’analisi di reti neurali applicate alla classificazione delle cifre del dataset MNIST, permettendo agli utenti di esplorare diverse configurazioni di reti e algoritmi di ottimizzazione, con particolare focus sulle varianti dell’algoritmo Rprop (STANDARD, RPROP_PLUS, IRPROP).\n",
    "\n",
    "## Sommario\n",
    "    \n",
    "    1. Estrazione e Preparazione del Dataset MNIST\n",
    "\t2. Configurazione delle Reti Neurali\n",
    "\t3. Addestramento con Varianti di Rprop\n",
    "\t4. Valutazione delle Prestazioni con Grafici\n",
    "\n",
    "## Configurazioni delle Reti Neurali\n",
    "\n",
    "Gli utenti possono personalizzare la struttura delle reti neurali scegliendo tra diverse configurazioni, inclusa la possibilità di definire:\n",
    "\n",
    "    • Dimensioni del training e del test set.\n",
    "\t• Numero di strati nascosti.\n",
    "\t• Numero di neuroni per strato.\n",
    "\t• Funzioni di attivazione per ciascun livello.\n",
    "\t\n",
    "## Personalizzazione dei Parametri di Addestramento\n",
    "\n",
    "Il quaderno permette una flessibile impostazione dei parametri di addestramento, quali:\n",
    "\n",
    "\t• Numero di epoche.\n",
    "\t• Tasso di apprendimento.\n",
    "\t• Suddivisione del set di addestramento.\n",
    "\t• Numero di ripetizioni, per eseguire più volte l’addestramento con una configurazione fissa, consentendo una valutazione più accurata degli algoritmi.\n",
    "\n",
    "## Algoritmi di Ottimizzazione Rprop\n",
    "\n",
    "Sono implementate diverse varianti dell’algoritmo di ottimizzazione Rprop, che possono essere confrontate in termini di efficienza e prestazioni durante l’addestramento delle reti neurali.\n",
    "\n",
    "## Valutazione delle Prestazioni delle Reti Neurali\n",
    "\n",
    "Il quaderno fornisce un’analisi completa delle prestazioni delle reti, con le seguenti metriche:\n",
    "       \n",
    "    • Tempo di impiegato per l'addestramento complessivo.\n",
    "\t• Errore sui set di addestramento e validazione.\n",
    "\t• Accuratezza sui set di addestramento, validazione e test.\n",
    "\t• Media, Varianza e Varianza Normalizzata delle Accuratezze sui set di test e addestramento.\n",
    "\t• Errore Assoluto Medio (MAE - Mean Absolute Error), Errore Quadratico Medio (RMSE - (Root Mean Squared Error), Accuratezza Media delle prestazioni su più ripetizioni, per valutare la stabilità e la consistenza degli algoritmi di ottimizzazione e delle configurazioni di rete.\n",
    "\t"
   ],
   "id": "1490f01ac98a5079"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\"\"\"\n",
    "    1. Estrazione e Preparazione del Dataset MNIST\n",
    "\"\"\"\n",
    "\n",
    "from nndlpy import MnistDataset as MnistDataset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\"\"\"\n",
    "    Init\n",
    "\"\"\"\n",
    "# Carica il dataset MNIST CSV con pandas\n",
    "train_data = pd.read_csv('data/mnist_train.csv')\n",
    "test_data = pd.read_csv('data/mnist_test.csv')\n",
    "\n",
    "# Converti i dati in array con numpy\n",
    "train_array = np.array(train_data)\n",
    "test_array = np.array(test_data)\n",
    "\n",
    "# Definisci le dimensioni del training e test set\n",
    "train_set_size = 50000  # Almeno 10.000 campioni per il training\n",
    "test_set_size = 10000    # Almeno 2.500 campioni per il test\n",
    "\n",
    "\"\"\"\n",
    "    Validation Set\n",
    "\"\"\"\n",
    "# Mescola i dati di training casualmente\n",
    "np.random.shuffle(train_array)\n",
    "# Calcola l'indice per il validation set (esempio: il 20% del training set)\n",
    "val_index = int(np.ceil(train_set_size * 0.20))\n",
    "# Estrai il validation set dal training array\n",
    "validation_array = train_array[:val_index - 1]\n",
    "# Estrai il validation set\n",
    "validation_X, validation_Y = MnistDataset.get_mnist_validation(validation_array)\n",
    "\n",
    "\"\"\"\n",
    "    Training Set\n",
    "\"\"\"\n",
    "# Estrai il training set rimanente (senza i dati di validation)\n",
    "train_array_reduced = train_array[val_index:train_set_size]\n",
    "# Estrai il training set (dopo aver rimosso i dati di validazione)\n",
    "train_X, train_Y = MnistDataset.get_mnist_training(train_array_reduced)\n",
    "\n",
    "\"\"\"\n",
    "    Test Set\n",
    "\"\"\"\n",
    "# Estrai il test set direttamente dal file di test\n",
    "test_X, test_Y = MnistDataset.get_mnist_test(test_array, test_set_size)\n",
    "\n",
    "print(\"\\nEstrazione e Preparazione del Dataset MNIST avvenuta con successo.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "    2. Configurazione delle Reti Neurali\n",
    "\"\"\"\n",
    "\n",
    "from nndlpy import ActivationFunctions as ActivationFunctions\n",
    "from nndlpy import LossFunctions as LossFunctions\n",
    "from nndlpy import NeuralNetwork as NeuralNetwork\n",
    "\n",
    "# Parametri di addestramento\n",
    "epochs = 35\n",
    "learning_rate = 0.00001\n",
    "num_of_networks = 5  # Definisci quante reti testare (maggiore di 0)\n",
    "\n",
    "# Funzioni di attivazione per i layer nascosti\n",
    "hidden_activation_funcs = [ActivationFunctions.relu]\n",
    "# Funzione di attivazione per l'output\n",
    "output_activation_func = ActivationFunctions.identity\n",
    "#Funzione di perdita per l'output\n",
    "loss_func = LossFunctions.cross_entropy_softmax\n",
    "\n",
    "# Numero di neuroni per ciascun layer nascosto\n",
    "hidden_layers_sizes = [32]\n",
    "\n",
    "# Dimensione dell'input e dell'output (numero di neuroni nel primo e ultimo layer)\n",
    "input_layer_size = train_X.shape[0]\n",
    "output_layer_size = train_Y.shape[0]\n",
    "\n",
    "# Creazione e inizializzazione delle reti neurali\n",
    "neural_networks = []\n",
    "\n",
    "for i in range(num_of_networks):\n",
    "    try:\n",
    "        # Inizializza una nuova rete neurale con la configurazione corrente\n",
    "        network = NeuralNetwork.NeuralNetwork(\n",
    "            hidden_activation_funcs,\n",
    "            output_activation_func,\n",
    "            loss_func,\n",
    "            input_layer_size,\n",
    "            hidden_layers_sizes,\n",
    "            output_layer_size\n",
    "        )\n",
    "        print(f\"Rete neurale {i+1} inizializzata con successo.\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Errore durante l'inizializzazione della rete {i+1}: {e}\")\n",
    "        continue\n",
    "    \n",
    "    # Aggiungi la rete neurale alla lista di reti\n",
    "    neural_networks.append(network)\n",
    "\n",
    "    # Modifica l'architettura rimuovendo l'ultima funzione di attivazione per la prossima rete (se necessario)\n",
    "    # if hidden_activation_funcs:\n",
    "    #     hidden_activation_funcs = hidden_activation_funcs[:-1]\n",
    "    \n",
    "# Mostra la struttura della prima rete\n",
    "print(\"\\nArchitettura della prima rete:\")\n",
    "neural_networks[0].get_network()"
   ],
   "id": "f1903c689d85edb6",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "    3. Addestramento con Varianti di Rprop (STANDARD, RPROP_PLUS, IRPROP)\n",
    "\"\"\"\n",
    "\n",
    "from src.nndlpy.NeuralNetwork import plot_metrics\n",
    "\n",
    "# Inizializza due liste vuote per memorizzare i risultati e le reti addestrate\n",
    "results_metrics = []\n",
    "trained_networks = []\n",
    "\n",
    "# Esegui il ciclo per il numero di reti specificato\n",
    "for run in range(num_of_networks):\n",
    "    # Clona la rete neurale corrente per l'addestramento\n",
    "    training_network = neural_networks[run].clone_network()\n",
    "    print(f'\\n\\n\\nEsecuzione numero {run + 1}\\n')\n",
    "\n",
    "    # Addestramento utilizzando Rprop(Rprop può assumere i seguenti valori: STANDARD, RPROP_PLUS, IRPROP)\n",
    "    metrics = training_network.train_model(train_X, train_Y, validation_X, validation_Y,\n",
    "                                           num_epochs=epochs, learning_rate=learning_rate,\n",
    "                                           rprop_method='STANDARD')\n",
    "\n",
    "    # Salva la rete addestrata e i risultati\n",
    "    trained_networks.append(training_network)\n",
    "    results_metrics.append(metrics)\n",
    "\n",
    "# Chiamata alla funzione di visualizzazione\n",
    "plot_metrics(results_metrics)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1cf190ffe477e656",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "    4. Valutazione delle Prestazioni con Grafici\n",
    "\"\"\"\n",
    "\n",
    "# Calcola le metriche \n",
    "    # MAE (Mean Absolute Error - Errore Assoluto Medio) \n",
    "    # RMSE (Root Mean Squared Error - Errore Quadratico Medio),\n",
    "    # Accuratezza \n",
    "# per le reti addestrate\n",
    "std_mae, std_rmse, std_accuracy = NeuralNetwork.metrics_mae_rmse_accuracy(results_metrics, epochs, num_of_networks)\n",
    "\n",
    "print(\"\\nErrore Assoluto Medio:\")\n",
    "print(f\"Media: {std_mae[-1]:.4f}\")\n",
    "\n",
    "print(\"\\nErrore Quadratico Medio:\")\n",
    "print(f\"Media: {std_rmse[-1]:.4f}\")\n",
    "\n",
    "print(\"\\nAccuratezza:\")\n",
    "print(f\"Media: {std_accuracy[-1]:.4f}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd91a036a32bc99",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Raccogli le accuratezze sui training e test set\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "num_of_networks = len(trained_networks)\n",
    "\n",
    "for run in range(num_of_networks):\n",
    "    train_accuracy = trained_networks[run].print_accuracies(f'\\nTraining Rprop - Run {run + 1}', test_X, test_Y, train_X, train_Y)\n",
    "    test_accuracy = trained_networks[run].print_accuracies(f'\\nTest Rprop - Run {run + 1}', test_X, test_Y, train_X, train_Y)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "# Calcola la media e la varianza delle accuratezze\n",
    "mean_train_accuracy = np.mean(train_accuracies)\n",
    "variance_train_accuracy = np.var(train_accuracies)\n",
    "normalized_variance_train_accuracy = variance_train_accuracy / mean_train_accuracy\n",
    "\n",
    "mean_test_accuracy = np.mean(test_accuracies)\n",
    "variance_test_accuracy = np.var(test_accuracies)\n",
    "normalized_variance_test_accuracy = variance_test_accuracy / mean_test_accuracy\n",
    "\n",
    "# Stampa i risultati\n",
    "print(f\"\\nMedia delle Accuratezze sui Training Set: {mean_train_accuracy:.5f}\")\n",
    "print(f\"Varianza delle Accuratezze sui Training Set: {variance_train_accuracy:.5f}\")\n",
    "print(f\"Varianza Normalizzata delle Accuratezze sui Training Set: {normalized_variance_train_accuracy:.5f}\")\n",
    "\n",
    "print(f\"\\nMedia delle Accuratezze sui Test Set: {mean_test_accuracy:.5f}\")\n",
    "print(f\"Varianza delle Accuratezze sui Test Set: {variance_test_accuracy:.5f}\")\n",
    "print(f\"Varianza Normalizzata delle Accuratezze sui Test Set: {normalized_variance_test_accuracy:.5f}\")\n",
    "\n",
    "# Visualizzazione grafica\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Grafico delle accuratezze di training\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(range(1, num_of_networks + 1), train_accuracies, color='lightgreen')\n",
    "plt.axhline(y=mean_train_accuracy, color='r', linestyle='--', label='Media delle Accuratezze')\n",
    "plt.title('Accuratezze sui Training Set per ogni Rete')\n",
    "plt.xlabel('Rete Neurale (Run)')\n",
    "plt.ylabel('Accuratezza')\n",
    "plt.xticks(range(1, num_of_networks + 1))\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "plt.grid(axis='y')\n",
    "\n",
    "# Grafico delle accuratezze di test\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(range(1, num_of_networks + 1), test_accuracies, color='skyblue')\n",
    "plt.axhline(y=mean_test_accuracy, color='r', linestyle='--', label='Media delle Accuratezze')\n",
    "plt.title('Accuratezze sui Test Set per ogni Rete')\n",
    "plt.xlabel('Rete Neurale (Run)')\n",
    "plt.ylabel('Accuratezza')\n",
    "plt.xticks(range(1, num_of_networks + 1))\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "plt.grid(axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "db1843a2f097f579",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
