{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Confronto tra l’algoritmo classico di RProp e le sue varianti per la classificazione di immagini MNIST\n",
    "\n",
    "Questo quaderno Jupyter offre un ambiente interattivo per l’addestramento e l’analisi di reti neurali applicate alla classificazione delle cifre del dataset MNIST, permettendo agli utenti di esplorare diverse configurazioni di reti e algoritmi di ottimizzazione, con particolare focus sulle varianti dell’algoritmo Rprop.\n",
    "\n",
    "## Sommario\n",
    "    \n",
    "    1. Estrazione e Preparazione del Dataset MNIST\n",
    "\t2. Configurazione delle Reti Neurali\n",
    "\t3. Addestramento con Varianti di Rprop\n",
    "\t4. Valutazione delle Prestazioni con Grafici\n",
    "\t5. Test Finale sul Set di Test\n",
    "\n",
    "## Configurazioni delle Reti Neurali\n",
    "\n",
    "Gli utenti possono personalizzare la struttura delle reti neurali scegliendo tra diverse configurazioni, inclusa la possibilità di definire:\n",
    "\n",
    "\t• Numero di strati nascosti.\n",
    "\t• Numero di neuroni per strato.\n",
    "\t• Funzioni di attivazione per ciascun livello.\n",
    "\t\n",
    "## Personalizzazione dei Parametri di Addestramento\n",
    "\n",
    "Il quaderno permette una flessibile impostazione dei parametri di addestramento, quali:\n",
    "\n",
    "\t• Numero di epoche.\n",
    "\t• Tasso di apprendimento.\n",
    "\t• Suddivisione del set di addestramento.\n",
    "\t•Numero di ripetizioni, per eseguire più volte l’addestramento con una configurazione fissa, consentendo una valutazione più accurata degli algoritmi.\n",
    "\n",
    "## Algoritmi di Ottimizzazione Rprop\n",
    "\n",
    "Sono implementate diverse varianti dell’algoritmo di ottimizzazione Rprop, che possono essere confrontate in termini di efficienza e prestazioni durante l’addestramento delle reti neurali.\n",
    "\n",
    "## Valutazione delle Prestazioni delle Reti Neurali\n",
    "\n",
    "Il quaderno fornisce un’analisi completa delle prestazioni delle reti, con le seguenti metriche:\n",
    "\n",
    "\t• Errore sui set di addestramento e validazione.\n",
    "\t• Accuratezza sui set di addestramento, validazione e test.\n",
    "\t• Tempo di esecuzione complessivo.\n",
    "\t• Media e varianza delle prestazioni su più ripetizioni, per valutare la stabilità e la consistenza degli algoritmi di ottimizzazione e delle configurazioni di rete."
   ],
   "id": "1490f01ac98a5079"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "is_executing": true
   },
   "source": [
    "\"\"\"\n",
    "    1. Estrazione e Preparazione del Dataset MNIST\n",
    "\"\"\"\n",
    "\n",
    "from nndlpy import MnistDataset as MnistDataset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\"\"\"\n",
    "    Init\n",
    "\"\"\"\n",
    "# Carica il dataset MNIST CSV con pandas\n",
    "train_data = pd.read_csv('data/mnist_train.csv')\n",
    "test_data = pd.read_csv('data/mnist_test.csv')\n",
    "\n",
    "# Converti i dati in array con numpy\n",
    "train_array = np.array(train_data)\n",
    "test_array = np.array(test_data)\n",
    "\n",
    "# Definisci le dimensioni del training set\n",
    "train_set_size = 10000  # Almeno 10.000 campioni per il training\n",
    "test_set_size = 2500    # Almeno 2.500 campioni per il test\n",
    "\n",
    "\"\"\"\n",
    "    Validation Set\n",
    "\"\"\"\n",
    "# Mescola i dati di training casualmente\n",
    "np.random.shuffle(train_array)\n",
    "# Calcola l'indice per il validation set (esempio: il 20% del training set)\n",
    "val_index = int(np.ceil(train_set_size * 0.20))\n",
    "# Estrai il validation set dal training array\n",
    "validation_array = train_array[:val_index - 1]\n",
    "# Estrai il validation set\n",
    "validation_X, validation_Y = MnistDataset.get_mnist_validation(validation_array)\n",
    "\n",
    "\"\"\"\n",
    "    Training Set\n",
    "\"\"\"\n",
    "# Estrai il training set rimanente (senza i dati di validation)\n",
    "train_array_reduced = train_array[val_index:train_set_size]\n",
    "# Estrai il training set (dopo aver rimosso i dati di validazione)\n",
    "train_X, train_Y = MnistDataset.get_mnist_training(train_array_reduced)\n",
    "\n",
    "\"\"\"\n",
    "    Test Set\n",
    "\"\"\"\n",
    "# Estrai il test set direttamente dal file di test\n",
    "test_X, test_Y = MnistDataset.get_mnist_test(test_array, test_set_size)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "    2. Configurazione delle Reti Neurali\n",
    "\"\"\"\n",
    "\n",
    "from nndlpy import ActivationFunctions as ActivationFunctions\n",
    "from nndlpy import LossFunctions as LossFunctions\n",
    "from nndlpy import NeuralNetwork as NeuralNetwork\n",
    "\n",
    "# Parametri di addestramento\n",
    "epochs = 35\n",
    "learning_rate = 0.00001\n",
    "num_of_networks = 5  # Definisci quante reti testare (maggiore di 0)\n",
    "\n",
    "# Funzioni di attivazione per i layer nascosti\n",
    "hidden_activation_funcs = [ActivationFunctions.relu]\n",
    "# Funzione di attivazione per l'output\n",
    "output_activation_func = ActivationFunctions.identity\n",
    "#Funzione di perdita per l'output\n",
    "loss_func = LossFunctions.cross_entropy_softmax\n",
    "\n",
    "# Numero di neuroni per ciascun layer nascosto\n",
    "hidden_layers_sizes = [32]\n",
    "\n",
    "# Dimensione dell'input e dell'output (numero di neuroni nel primo e ultimo layer)\n",
    "input_layer_size = train_X.shape[0]\n",
    "output_layer_size = train_Y.shape[0]\n",
    "\n",
    "# Creazione e inizializzazione delle reti neurali\n",
    "neural_networks = []\n",
    "\n",
    "for i in range(num_of_networks):\n",
    "    try:\n",
    "        # Inizializza una nuova rete neurale con la configurazione corrente\n",
    "        network = NeuralNetwork.NeuralNetwork(\n",
    "            hidden_activation_funcs,\n",
    "            output_activation_func,\n",
    "            loss_func,\n",
    "            input_layer_size,\n",
    "            hidden_layers_sizes,\n",
    "            output_layer_size\n",
    "        )\n",
    "        print(f\"Rete neurale {i+1} inizializzata con successo.\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Errore durante l'inizializzazione della rete {i+1}: {e}\")\n",
    "        continue\n",
    "    \n",
    "    # Aggiungi la rete neurale alla lista di reti\n",
    "    neural_networks.append(network)\n",
    "\n",
    "    # Modifica l'architettura rimuovendo l'ultima funzione di attivazione per la prossima rete (se necessario)\n",
    "    # if hidden_activation_funcs:\n",
    "    #     hidden_activation_funcs = hidden_activation_funcs[:-1]\n",
    "    \n",
    "# Mostra la struttura della prima rete\n",
    "print(\"\\nArchitettura della prima rete:\")\n",
    "neural_networks[0].get_network() "
   ],
   "id": "f1903c689d85edb6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Inizializza liste vuote per raccogliere i risultati e le reti addestrate\n",
    "results_list = []\n",
    "trained_networks = []\n",
    "\n",
    "for run in range(num_of_networks):\n",
    "    # Crea una copia della rete neurale da addestrare\n",
    "    current_network = neural_networks[run].clone_network()\n",
    "\n",
    "    print(f'\\nInizio del run numero {run + 1}\\n')\n",
    "\n",
    "    # Addestra la rete usando il metodo di Rprop (Rprop può assumere i seguenti valori: STANDARD, RPROP_PLUS, IRPROP)\n",
    "    metrics = current_network.train(\n",
    "        train_X,\n",
    "        train_Y,\n",
    "        validation_X,\n",
    "        validation_Y,\n",
    "        epochs=epochs,\n",
    "        learning_rate=learning_rate,\n",
    "        rprop_type='STANDARD'\n",
    "    )\n",
    "\n",
    "    # Aggiungi la rete addestrata e i suoi risultati alle rispettive liste\n",
    "    trained_networks.append(current_network)\n",
    "    results_list.append(metrics)"
   ],
   "id": "cdbc0491828c4e42",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Chiama la funzione per calcolare MAE, RMSE e accuratezza\n",
    "std_mae, std_rmse, std_accuracy = NeuralNetwork.metrics_mae_rmse_accuracy(results_list, epochs, num_of_networks)\n",
    "\n",
    "# Stampa delle ultime metriche\n",
    "print(\"\\nUltime metriche per MAE:\")\n",
    "print(std_mae[-1])\n",
    "\n",
    "print(\"\\nUltime metriche per RMSE:\")\n",
    "print(std_rmse[-1])\n",
    "\n",
    "print(\"\\nUltime metriche per Accuratezza:\")\n",
    "print(std_accuracy[-1])"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
